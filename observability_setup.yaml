# ==============================================================================
# COMPLETE OPENTELEMETRY OBSERVABILITY SETUP FOR KUBERNETES
# Components: Grafana Alloy, Tempo, Loki, Prometheus, Grafana
# All fixes applied: RBAC, Volume Mounts, Persistent Storage
# ==============================================================================

---
# ==============================================================================
# 1. NAMESPACE
# ==============================================================================
apiVersion: v1
kind: Namespace
metadata:
  name: observability

---
# ==============================================================================
# 2. PERSISTENT VOLUME CLAIMS
# ==============================================================================
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: loki-storage
  namespace: observability
spec:
  accessModes:
    - ReadWriteOnce
  resources:
    requests:
      storage: 10Gi

---
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: tempo-storage
  namespace: observability
spec:
  accessModes:
    - ReadWriteOnce
  resources:
    requests:
      storage: 10Gi

---
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: prometheus-storage
  namespace: observability
spec:
  accessModes:
    - ReadWriteOnce
  resources:
    requests:
      storage: 10Gi

---
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: grafana-storage
  namespace: observability
spec:
  accessModes:
    - ReadWriteOnce
  resources:
    requests:
      storage: 5Gi

---
# ==============================================================================
# 3. GRAFANA TEMPO - Distributed Tracing Backend (OTLP Only)
# ==============================================================================
apiVersion: v1
kind: ConfigMap
metadata:
  name: tempo-config
  namespace: observability
data:
  tempo.yaml: |
    server:
      http_listen_port: 3200
      log_level: info
    
    distributor:
      receivers:
        otlp:
          protocols:
            grpc:
              endpoint: 0.0.0.0:4317
            http:
              endpoint: 0.0.0.0:4318
    
    ingester:
      max_block_duration: 5m
      trace_idle_period: 10s
      max_block_bytes: 1000000
    
    compactor:
      compaction:
        block_retention: 48h
    
    storage:
      trace:
        backend: local
        local:
          path: /var/tempo/traces
        wal:
          path: /var/tempo/wal
        pool:
          max_workers: 100
          queue_depth: 10000
    
    query_frontend:
      search:
        max_duration: 15m
      trace_by_id:
        query_shards: 2
    
    metrics_generator:
      registry:
        external_labels:
          source: tempo
          cluster: kubernetes
      storage:
        path: /var/tempo/generator/wal
        remote_write:
          - url: http://prometheus.observability.svc.cluster.local:9090/api/v1/write
            send_exemplars: true

---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: tempo
  namespace: observability
spec:
  replicas: 1
  selector:
    matchLabels:
      app: tempo
  template:
    metadata:
      labels:
        app: tempo
    spec:
      initContainers:
      - name: init-tempo-dirs
        image: busybox:latest
        command:
        - sh
        - -c
        - |
          mkdir -p /var/tempo/traces /var/tempo/wal /var/tempo/generator/wal
          chmod -R 777 /var/tempo
        volumeMounts:
        - name: tempo-storage
          mountPath: /var/tempo
      containers:
      - name: tempo
        image: grafana/tempo:latest
        args:
          - -config.file=/etc/tempo/tempo.yaml
          - -target=all
        ports:
        - containerPort: 3200
          name: http
        - containerPort: 4317
          name: otlp-grpc
        - containerPort: 4318
          name: otlp-http
        volumeMounts:
        - name: tempo-config
          mountPath: /etc/tempo
        - name: tempo-storage
          mountPath: /var/tempo
        resources:
          requests:
            cpu: 100m
            memory: 256Mi
          limits:
            cpu: 1000m
            memory: 2Gi
      volumes:
      - name: tempo-config
        configMap:
          name: tempo-config
      - name: tempo-storage
        persistentVolumeClaim:
          claimName: tempo-storage

---
apiVersion: v1
kind: Service
metadata:
  name: tempo
  namespace: observability
spec:
  selector:
    app: tempo
  ports:
  - name: http
    port: 3200
    targetPort: 3200
  - name: otlp-grpc
    port: 4317
    targetPort: 4317
  - name: otlp-http
    port: 4318
    targetPort: 4318
  type: ClusterIP

---
# ==============================================================================
# 4. LOKI - Log Aggregation System
# ==============================================================================
apiVersion: v1
kind: ConfigMap
metadata:
  name: loki-config
  namespace: observability
data:
  loki.yaml: |
    auth_enabled: false
    
    server:
      http_listen_port: 3100
      grpc_listen_port: 9096
      log_level: info
    
    common:
      path_prefix: /loki
      storage:
        filesystem:
          chunks_directory: /loki/chunks
          rules_directory: /loki/rules
      replication_factor: 1
      ring:
        instance_addr: 127.0.0.1
        kvstore:
          store: inmemory
    
    schema_config:
      configs:
        - from: 2020-10-24
          store: tsdb
          object_store: filesystem
          schema: v13
          index:
            prefix: index_
            period: 24h
    
    limits_config:
      retention_period: 744h
      ingestion_rate_mb: 100
      ingestion_burst_size_mb: 200
      max_entries_limit_per_query: 5000
      max_streams_per_user: 0
      max_global_streams_per_user: 0
      reject_old_samples: false
      reject_old_samples_max_age: 168h

---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: loki
  namespace: observability
spec:
  replicas: 1
  selector:
    matchLabels:
      app: loki
  template:
    metadata:
      labels:
        app: loki
    spec:
      securityContext:
        fsGroup: 10001
        runAsUser: 10001
        runAsNonRoot: true
      containers:
      - name: loki
        image: grafana/loki:latest
        args:
          - -config.file=/etc/loki/loki.yaml
        ports:
        - containerPort: 3100
          name: http
        - containerPort: 9096
          name: grpc
        volumeMounts:
        - name: loki-config
          mountPath: /etc/loki
        - name: loki-storage
          mountPath: /loki
        resources:
          requests:
            cpu: 100m
            memory: 256Mi
          limits:
            cpu: 500m
            memory: 1Gi
        livenessProbe:
          httpGet:
            path: /ready
            port: 3100
          initialDelaySeconds: 45
          periodSeconds: 10
        readinessProbe:
          httpGet:
            path: /ready
            port: 3100
          initialDelaySeconds: 45
          periodSeconds: 10
      volumes:
      - name: loki-config
        configMap:
          name: loki-config
      - name: loki-storage
        persistentVolumeClaim:
          claimName: loki-storage

---
apiVersion: v1
kind: Service
metadata:
  name: loki
  namespace: observability
spec:
  selector:
    app: loki
  ports:
  - name: http
    port: 3100
    targetPort: 3100
  - name: grpc
    port: 9096
    targetPort: 9096
  type: ClusterIP

---
# ==============================================================================
# 5. PROMETHEUS - Metrics Storage
# ==============================================================================
apiVersion: v1
kind: ConfigMap
metadata:
  name: prometheus-config
  namespace: observability
data:
  prometheus.yml: |
    global:
      scrape_interval: 15s
      evaluation_interval: 15s
      external_labels:
        cluster: 'kubernetes'
    
    scrape_configs:
      - job_name: 'prometheus'
        static_configs:
          - targets: ['localhost:9090']
          
      - job_name: 'todo-app'
        static_configs:
          - targets: ['todo-app-service.default.svc.cluster.local:5000']
        metrics_path: '/metrics'
      
      # Automatically scrape all pods (new)
      - job_name: 'kubernetes-nodes'
        scheme: https
        tls_config:
          insecure_skip_verify: true
        kubernetes_sd_configs:
          - role: node
        bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token
        relabel_configs:
          - action: labelmap
            regex: __meta_kubernetes_node_label_(.+)
          # Use the node name as the instance label
          - source_labels: [__meta_kubernetes_node_name]
            target_label: instance
          - target_label: __address__
            replacement: kubernetes.default.svc:443
          - source_labels: [__meta_kubernetes_node_name]
            regex: (.+)
            target_label: __metrics_path__
            replacement: /api/v1/nodes/${1}/proxy/metrics
      
      # Node cadvisor metrics (for container metrics)
      - job_name: 'kubernetes-cadvisor'
        scheme: https
        tls_config:
          insecure_skip_verify: true
        kubernetes_sd_configs:
          - role: node
        bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token
        relabel_configs:
          - action: labelmap
            regex: __meta_kubernetes_node_label_(.+)
          # Use the node name as the instance label
          - source_labels: [__meta_kubernetes_node_name]
            target_label: instance
          - target_label: __address__
            replacement: kubernetes.default.svc:443
          - source_labels: [__meta_kubernetes_node_name]
            regex: (.+)
            target_label: __metrics_path__
            replacement: /api/v1/nodes/${1}/proxy/metrics/cadvisor
            
      - job_name: 'kubernetes-pods-auto'
        kubernetes_sd_configs:
          - role: pod
        relabel_configs:
          # Skip pods that have an annotation explicitly setting scrape to false
          - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_scrape]
            action: drop
            regex: "false"
          # Set metrics path
          - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_path]
            action: replace
            target_label: __metrics_path__
            regex: (.+)
            replacement: ${1}
          # Skip if no ports are defined for the pod
          - source_labels: [__meta_kubernetes_pod_container_port_name]
            regex: ""
            action: drop
          # For pods with a port named "metrics" or "http", use that port
          - source_labels: [__address__, __meta_kubernetes_pod_container_port_name]
            action: replace
            regex: (.+);(metrics|http|web)
            replacement: ${1}:${2}
            target_label: __address__
          # For other pods, try port 8080 or use the first defined port
          - source_labels: [__address__, __meta_kubernetes_pod_container_port_number]
            action: replace
            regex: (.+);(8080)
            replacement: ${1}:${2}
            target_label: __address__
          # Add useful labels
          - action: labelmap
            regex: __meta_kubernetes_pod_label_(.+)
          - source_labels: [__meta_kubernetes_namespace]
            action: replace
            target_label: namespace
          - source_labels: [__meta_kubernetes_pod_name]
            action: replace
            target_label: pod
          - source_labels: [__meta_kubernetes_pod_container_name]
            action: replace
            target_label: container
      
      - job_name: 'kubernetes-pods'
        kubernetes_sd_configs:
          - role: pod
        relabel_configs:
          - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_scrape]
            action: keep
            regex: true
          - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_scheme]
            action: replace
            target_label: __scheme__
            regex: (https?)
            replacement: ${1}
          - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_path]
            action: replace
            target_label: __metrics_path__
            regex: (.+)
            replacement: ${1}
          - source_labels: [__address__, __meta_kubernetes_pod_annotation_prometheus_io_port]
            action: replace
            regex: ([^:]+)(?::\d+)?;(\d+)
            replacement: $1:$2
            target_label: __address__
          - action: labelmap
            regex: __meta_kubernetes_pod_label_(.+)
          - source_labels: [__meta_kubernetes_namespace]
            action: replace
            target_label: namespace
          - source_labels: [__meta_kubernetes_pod_name]
            action: replace
            target_label: pod
          - source_labels: [__meta_kubernetes_pod_container_name]
            action: replace
            target_label: container
      
      - job_name: 'kubernetes-services'
        kubernetes_sd_configs:
          - role: service
        relabel_configs:
          - source_labels: [__meta_kubernetes_service_annotation_prometheus_io_scrape]
            action: keep
            regex: true
          - source_labels: [__meta_kubernetes_service_annotation_prometheus_io_scheme]
            action: replace
            target_label: __scheme__
            regex: (https?)
            replacement: ${1}
          - source_labels: [__meta_kubernetes_service_annotation_prometheus_io_path]
            action: replace
            target_label: __metrics_path__
            regex: (.+)
            replacement: ${1}
          - source_labels: [__address__, __meta_kubernetes_service_annotation_prometheus_io_port]
            action: replace
            regex: ([^:]+)(?::\d+)?;(\d+)
            replacement: $1:$2
            target_label: __address__
          - action: labelmap
            regex: __meta_kubernetes_service_label_(.+)
          - source_labels: [__meta_kubernetes_namespace]
            action: replace
            target_label: namespace
          - source_labels: [__meta_kubernetes_service_name]
            action: replace
            target_label: service
      
      - job_name: 'kubernetes-endpoints'
        kubernetes_sd_configs:
          - role: endpoints
        relabel_configs:
          - source_labels: [__meta_kubernetes_service_annotation_prometheus_io_scrape]
            action: keep
            regex: true
          - source_labels: [__meta_kubernetes_service_annotation_prometheus_io_scheme]
            action: replace
            target_label: __scheme__
            regex: (https?)
            replacement: ${1}
          - source_labels: [__meta_kubernetes_service_annotation_prometheus_io_path]
            action: replace
            target_label: __metrics_path__
            regex: (.+)
            replacement: ${1}
          - source_labels: [__address__, __meta_kubernetes_service_annotation_prometheus_io_port]
            action: replace
            regex: ([^:]+)(?::\d+)?;(\d+)
            replacement: $1:$2
            target_label: __address__
          - action: labelmap
            regex: __meta_kubernetes_service_label_(.+)
          - source_labels: [__meta_kubernetes_namespace]
            action: replace
            target_label: namespace
          - source_labels: [__meta_kubernetes_service_name]
            action: replace
            target_label: service
          - source_labels: [__meta_kubernetes_pod_name]
            action: replace
            target_label: pod

---
apiVersion: v1
kind: ServiceAccount
metadata:
  name: prometheus
  namespace: observability

---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  name: prometheus
rules:
- apiGroups: [""]
  resources:
  - nodes
  - nodes/proxy
  - nodes/metrics
  - services
  - endpoints
  - pods
  verbs: ["get", "list", "watch"]
- apiGroups: [""]
  resources:
  - configmaps
  verbs: ["get"]
- apiGroups: ["networking.k8s.io"]
  resources:
  - ingresses
  verbs: ["get", "list", "watch"]
- nonResourceURLs: ["/metrics", "/metrics/cadvisor"]
  verbs: ["get"]

---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: prometheus
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: prometheus
subjects:
- kind: ServiceAccount
  name: prometheus
  namespace: observability

---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: prometheus
  namespace: observability
spec:
  replicas: 1
  strategy:
    type: RollingUpdate
    rollingUpdate:
      maxSurge: 1
      maxUnavailable: 0
  selector:
    matchLabels:
      app: prometheus
  template:
    metadata:
      labels:
        app: prometheus
    spec:
      serviceAccountName: prometheus
      containers:
      - name: prometheus
        image: prom/prometheus:latest
        args:
          - '--config.file=/etc/prometheus/prometheus.yml'
          - '--storage.tsdb.path=/prometheus'
          - '--storage.tsdb.retention.time=15d'
          - '--web.console.libraries=/usr/share/prometheus/console_libraries'
          - '--web.console.templates=/usr/share/prometheus/consoles'
          - '--web.enable-lifecycle'
        ports:
        - containerPort: 9090
          name: http
        volumeMounts:
        - name: prometheus-config
          mountPath: /etc/prometheus
        - name: prometheus-storage
          mountPath: /prometheus
        resources:
          requests:
            cpu: 200m
            memory: 512Mi
          limits:
            cpu: 1000m
            memory: 2Gi
      volumes:
      - name: prometheus-config
        configMap:
          name: prometheus-config
      - name: prometheus-storage
        persistentVolumeClaim:
          claimName: prometheus-storage

---
apiVersion: v1
kind: Service
metadata:
  name: prometheus
  namespace: observability
spec:
  selector:
    app: prometheus
  ports:
  - name: http
    port: 9090
    targetPort: 9090
  type: ClusterIP

---
# ==============================================================================
# 6. GRAFANA - Visualization Platform
# ==============================================================================
apiVersion: v1
kind: ConfigMap
metadata:
  name: grafana-datasources
  namespace: observability
data:
  datasources.yaml: |
    apiVersion: 1
    datasources:
      - name: Prometheus
        type: prometheus
        access: proxy
        url: http://prometheus.observability.svc.cluster.local:9090
        isDefault: true
        editable: true
        jsonData:
          timeInterval: 15s
      
      - name: Loki
        type: loki
        access: proxy
        url: http://loki.observability.svc.cluster.local:3100
        editable: true
        jsonData:
          maxLines: 1000
      
      - name: Tempo
        type: tempo
        access: proxy
        url: http://tempo.observability.svc.cluster.local:3200
        editable: true
        jsonData:
          tracesToLogsV2:
            datasourceUid: 'loki'
            spanStartTimeShift: '-1h'
            spanEndTimeShift: '1h'
            filterByTraceID: true
            filterBySpanID: false
            tags: ['container', 'pod', 'namespace']
          tracesToMetrics:
            datasourceUid: 'prometheus'
            queries:
              - name: "Request Rate"
                query: 'sum(rate(todo_request_count_total{namespace="$namespace", pod="$pod"}[5m])) by (endpoint)'
              - name: "Error Rate"
                query: 'sum(rate(todo_request_count_total{namespace="$namespace", pod="$pod", http_status=~"5.."}[5m])) by (endpoint)'
          serviceMap:
            datasourceUid: 'prometheus'
          nodeGraph:
            enabled: true
          search:
            hide: false
          lokiSearch:
            datasourceUid: 'loki'
          traceQuery:
            timeShiftEnabled: true
            spanStartTimeShift: '1h'
            spanEndTimeShift: '-1h'
          spanBar:
            type: 'Tag'
            tag: 'http.status_code'
          queryType: "traceql"
          traceQLSearchType: "trace"

---
# ==============================================================================
# GRAFANA DASHBOARDS FOR KUBERNETES OBSERVABILITY
# Includes: Metrics, Logs, and Traces Dashboards
# ==============================================================================

---
# ==============================================================================
# 1. DASHBOARD PROVISIONING CONFIGMAP
# ==============================================================================
apiVersion: v1
kind: ConfigMap
metadata:
  name: grafana-dashboard-provisioning
  namespace: observability
data:
  dashboards.yaml: |
    apiVersion: 1
    providers:
      - name: 'default'
        orgId: 1
        folder: 'Kubernetes'
        type: file
        disableDeletion: false
        updateIntervalSeconds: 10
        allowUiUpdates: true
        options:
          path: /var/lib/grafana/dashboards

---
# ==============================================================================
# 2. KUBERNETES METRICS DASHBOARD
# ==============================================================================
apiVersion: v1
kind: ConfigMap
metadata:
  name: grafana-dashboard-k8s-metrics
  namespace: observability
data:
  k8s-metrics.json: |
    {
      "title": "Kubernetes Cluster Metrics",
      "uid": "k8s-metrics",
      "timezone": "browser",
      "refresh": "10s",
      "time": {
        "from": "now-1h",
        "to": "now"
      },
        "templating": {
          "list": [
            {
              "name": "datasource",
              "type": "datasource",
              "query": "prometheus",
              "current": {
                "text": "Prometheus",
                "value": "Prometheus"
              },
              "hide": 0
            },
            {
              "name": "namespace",
              "type": "query",
              "datasource": "$datasource",
              "query": "label_values(kube_pod_info, namespace)",
              "refresh": 2,
              "multi": true,
              "includeAll": true,
              "allValue": ".*",
              "current": {
                "text": "All",
                "value": "$__all"
              }
            },
            {
              "name": "pod",
              "type": "query",
              "datasource": "$datasource",
              "query": "label_values(kube_pod_info{namespace=~\"$namespace\"}, pod)",
              "refresh": 2,
              "multi": true,
              "includeAll": true,
              "allValue": ".*",
              "current": {
                "text": "All",
                "value": "$__all"
              }
            },
            {
              "name": "container",
              "type": "query",
              "datasource": "$datasource",
              "query": "label_values(kube_pod_container_info{namespace=~\"$namespace\", pod=~\"$pod\"}, container)",
              "refresh": 2,
              "multi": true,
              "includeAll": true,
              "allValue": ".*",
              "current": {
                "text": "All",
                "value": "$__all"
              }
            }
          ]
        },
        "panels": [
          {
            "title": "CPU Usage by Container",
            "gridPos": { "h": 8, "w": 12, "x": 0, "y": 0 },
            "type": "graph",
            "datasource": "$datasource",
            "targets": [
              {
                "expr": "sum(rate(container_cpu_usage_seconds_total{namespace=~\"$namespace\", pod=~\"$pod\", container=~\"$container\", container!=\"\"}[5m])) by (namespace, pod, container)",
                "legendFormat": "{{namespace}}/{{pod}}/{{container}}",
                "refId": "A"
              }
            ],
            "yaxes": [
              {
                "format": "short",
                "label": "CPU Cores"
              },
              {
                "format": "short"
              }
            ]
          },
          {
            "title": "CPU Usage Percentage",
            "gridPos": { "h": 8, "w": 12, "x": 12, "y": 0 },
            "type": "graph",
            "datasource": "$datasource",
            "targets": [
              {
                "expr": "sum(rate(container_cpu_usage_seconds_total{namespace=~\"$namespace\", pod=~\"$pod\", container=~\"$container\", container!=\"\"}[5m])) by (namespace, pod, container) / sum(container_spec_cpu_quota{namespace=~\"$namespace\", pod=~\"$pod\", container=~\"$container\", container!=\"\"}/container_spec_cpu_period{namespace=~\"$namespace\", pod=~\"$pod\", container=~\"$container\", container!=\"\"}) by (namespace, pod, container) * 100",
                "legendFormat": "{{namespace}}/{{pod}}/{{container}}",
                "refId": "A"
              }
            ],
            "yaxes": [
              {
                "format": "percent",
                "label": "CPU %"
              },
              {
                "format": "short"
              }
            ]
          },
          {
            "title": "Memory Usage",
            "gridPos": { "h": 8, "w": 12, "x": 0, "y": 8 },
            "type": "graph",
            "datasource": "$datasource",
            "targets": [
              {
                "expr": "sum(container_memory_working_set_bytes{namespace=~\"$namespace\", pod=~\"$pod\", container=~\"$container\", container!=\"\"}) by (namespace, pod, container)",
                "legendFormat": "{{namespace}}/{{pod}}/{{container}}",
                "refId": "A"
              }
            ],
            "yaxes": [
              {
                "format": "bytes",
                "label": "Memory"
              },
              {
                "format": "short"
              }
            ]
          },
          {
            "title": "Memory Usage Percentage",
            "gridPos": { "h": 8, "w": 12, "x": 12, "y": 8 },
            "type": "graph",
            "datasource": "$datasource",
            "targets": [
              {
                "expr": "sum(container_memory_working_set_bytes{namespace=~\"$namespace\", pod=~\"$pod\", container=~\"$container\", container!=\"\"}) by (namespace, pod, container) / sum(container_spec_memory_limit_bytes{namespace=~\"$namespace\", pod=~\"$pod\", container=~\"$container\", container!=\"\"}) by (namespace, pod, container) * 100",
                "legendFormat": "{{namespace}}/{{pod}}/{{container}}",
                "refId": "A"
              }
            ],
            "yaxes": [
              {
                "format": "percent",
                "label": "Memory %"
              },
              {
                "format": "short"
              }
            ]
          },
          {
            "title": "Network I/O",
            "gridPos": { "h": 8, "w": 12, "x": 0, "y": 16 },
            "type": "graph",
            "datasource": "$datasource",
            "targets": [
              {
                "expr": "sum(rate(container_network_receive_bytes_total{namespace=~\"$namespace\", pod=~\"$pod\"}[5m])) by (namespace, pod)",
                "legendFormat": "RX: {{namespace}}/{{pod}}",
                "refId": "A"
              },
              {
                "expr": "-sum(rate(container_network_transmit_bytes_total{namespace=~\"$namespace\", pod=~\"$pod\"}[5m])) by (namespace, pod)",
                "legendFormat": "TX: {{namespace}}/{{pod}}",
                "refId": "B"
              }
            ],
            "yaxes": [
              {
                "format": "Bps",
                "label": "Bytes/sec"
              },
              {
                "format": "short"
              }
            ]
          },
          {
            "title": "Filesystem Usage",
            "gridPos": { "h": 8, "w": 12, "x": 12, "y": 16 },
            "type": "graph",
            "datasource": "$datasource",
            "targets": [
              {
                "expr": "sum(container_fs_usage_bytes{namespace=~\"$namespace\", pod=~\"$pod\", container=~\"$container\", container!=\"\"}) by (namespace, pod, container)",
                "legendFormat": "{{namespace}}/{{pod}}/{{container}}",
                "refId": "A"
              }
            ],
            "yaxes": [
              {
                "format": "bytes",
                "label": "Disk Usage"
              },
              {
                "format": "short"
              }
            ]
          },
          {
            "title": "Pod Restart Count",
            "gridPos": { "h": 8, "w": 12, "x": 0, "y": 24 },
            "type": "graph",
            "datasource": "$datasource",
            "targets": [
              {
                "expr": "sum(kube_pod_container_status_restarts_total{namespace=~\"$namespace\", pod=~\"$pod\", container=~\"$container\"}) by (namespace, pod, container)",
                "legendFormat": "{{namespace}}/{{pod}}/{{container}}",
                "refId": "A"
              }
            ],
            "yaxes": [
              {
                "format": "short",
                "label": "Restarts"
              },
              {
                "format": "short"
              }
            ]
          },
          {
            "title": "Container States",
            "gridPos": { "h": 8, "w": 12, "x": 12, "y": 24 },
            "type": "stat",
            "datasource": "$datasource",
            "targets": [
              {
                "expr": "sum(kube_pod_container_status_running{namespace=~\"$namespace\", pod=~\"$pod\", container=~\"$container\"})",
                "legendFormat": "Running",
                "refId": "A"
              },
              {
                "expr": "sum(kube_pod_container_status_waiting{namespace=~\"$namespace\", pod=~\"$pod\", container=~\"$container\"})",
                "legendFormat": "Waiting",
                "refId": "B"
              },
              {
                "expr": "sum(kube_pod_container_status_terminated{namespace=~\"$namespace\", pod=~\"$pod\", container=~\"$container\"})",
                "legendFormat": "Terminated",
                "refId": "C"
              }
            ],
            "options": {
              "orientation": "horizontal",
              "colorMode": "background",
              "graphMode": "none"
            }
          }
        ]
      }
    }

---
# ==============================================================================
# 3. KUBERNETES LOGS DASHBOARD
# ==============================================================================
apiVersion: v1
kind: ConfigMap
metadata:
  name: grafana-dashboard-k8s-logs
  namespace: observability
data:
  k8s-logs.json: |
    {
      "title": "Kubernetes Container Logs",
      "uid": "k8s-logs",
      "timezone": "browser",
      "refresh": "10s",
      "time": {
        "from": "now-1h",
        "to": "now"
      },
        "templating": {
          "list": [
            {
              "name": "datasource",
              "type": "datasource",
              "query": "loki",
              "current": {
                "text": "Loki",
                "value": "Loki"
              },
              "hide": 0
            },
            {
              "name": "namespace",
              "type": "query",
              "datasource": "$datasource",
              "query": "label_values(namespace)",
              "refresh": 2,
              "multi": false,
              "includeAll": true,
              "allValue": ".*",
              "current": {
                "text": "All",
                "value": "$__all"
              }
            },
            {
              "name": "pod",
              "type": "query",
              "datasource": "$datasource",
              "query": "label_values({namespace=~\"$namespace\"}, pod)",
              "refresh": 2,
              "multi": false,
              "includeAll": true,
              "allValue": ".*",
              "current": {
                "text": "All",
                "value": "$__all"
              }
            },
            {
              "name": "container",
              "type": "query",
              "datasource": "$datasource",
              "query": "label_values({namespace=~\"$namespace\", pod=~\"$pod\"}, container)",
              "refresh": 2,
              "multi": false,
              "includeAll": true,
              "allValue": ".*",
              "current": {
                "text": "All",
                "value": "$__all"
              }
            },
            {
              "name": "log_level",
              "type": "custom",
              "query": "all,debug,info,warn,error,fatal",
              "multi": false,
              "current": {
                "text": "all",
                "value": "all"
              }
            },
            {
              "name": "search",
              "type": "textbox",
              "query": "",
              "current": {
                "text": "",
                "value": ""
              }
            }
          ]
        },
        "panels": [
          {
            "title": "Log Volume Over Time",
            "gridPos": { "h": 8, "w": 24, "x": 0, "y": 0 },
            "type": "graph",
            "datasource": "$datasource",
            "targets": [
              {
                "expr": "sum(rate({namespace=~\"$namespace\", pod=~\"$pod\", container=~\"$container\"} |~ \"(?i)$log_level\" |~ \"$search\" [5m])) by (namespace, pod, container)",
                "legendFormat": "{{namespace}}/{{pod}}/{{container}}",
                "refId": "A"
              }
            ],
            "yaxes": [
              {
                "format": "short",
                "label": "Logs/sec"
              },
              {
                "format": "short"
              }
            ]
          },
          {
            "title": "Container Logs Stream",
            "gridPos": { "h": 16, "w": 24, "x": 0, "y": 8 },
            "type": "logs",
            "datasource": "$datasource",
            "targets": [
              {
                "expr": "{namespace=~\"$namespace\", pod=~\"$pod\", container=~\"$container\"} |~ \"(?i)$log_level\" |~ \"$search\"",
                "refId": "A"
              }
            ],
            "options": {
              "showTime": true,
              "showLabels": true,
              "showCommonLabels": false,
              "wrapLogMessage": false,
              "sortOrder": "Descending",
              "dedupStrategy": "none",
              "enableLogDetails": true,
              "prettifyLogMessage": false
            }
          },
          {
            "title": "Error Logs",
            "gridPos": { "h": 8, "w": 12, "x": 0, "y": 24 },
            "type": "logs",
            "datasource": "$datasource",
            "targets": [
              {
                "expr": "{namespace=~\"$namespace\", pod=~\"$pod\", container=~\"$container\"} |~ \"(?i)(error|err|fail|exception|panic|fatal)\"",
                "refId": "A"
              }
            ],
            "options": {
              "showTime": true,
              "showLabels": false,
              "dedupStrategy": "none",
              "wrapLogMessage": false
            }
          },
          {
            "title": "Warning Logs",
            "gridPos": { "h": 8, "w": 12, "x": 12, "y": 24 },
            "type": "logs",
            "datasource": "$datasource",
            "targets": [
              {
                "expr": "{namespace=~\"$namespace\", pod=~\"$pod\", container=~\"$container\"} |~ \"(?i)(warn|warning)\"",
                "refId": "A"
              }
            ],
            "options": {
              "showTime": true,
              "showLabels": false,
              "dedupStrategy": "none",
              "wrapLogMessage": false
            }
          },
          {
            "title": "Log Distribution by Level",
            "gridPos": { "h": 8, "w": 12, "x": 0, "y": 32 },
            "type": "piechart",
            "datasource": "$datasource",
            "targets": [
              {
                "expr": "sum(count_over_time({namespace=~\"$namespace\", pod=~\"$pod\", container=~\"$container\"} |~ \"(?i)error\" [1h]))",
                "legendFormat": "Error",
                "refId": "A"
              },
              {
                "expr": "sum(count_over_time({namespace=~\"$namespace\", pod=~\"$pod\", container=~\"$container\"} |~ \"(?i)warn\" [1h]))",
                "legendFormat": "Warning",
                "refId": "B"
              },
              {
                "expr": "sum(count_over_time({namespace=~\"$namespace\", pod=~\"$pod\", container=~\"$container\"} |~ \"(?i)info\" [1h]))",
                "legendFormat": "Info",
                "refId": "C"
              },
              {
                "expr": "sum(count_over_time({namespace=~\"$namespace\", pod=~\"$pod\", container=~\"$container\"} |~ \"(?i)debug\" [1h]))",
                "legendFormat": "Debug",
                "refId": "D"
              }
            ],
            "options": {
              "pieType": "donut",
              "displayLabels": ["name", "percent"],
              "legendDisplayMode": "list",
              "legendPlacement": "right"
            }
          },
          {
            "title": "Top Logging Containers",
            "gridPos": { "h": 8, "w": 12, "x": 12, "y": 32 },
            "type": "bargauge",
            "datasource": "$datasource",
            "targets": [
              {
                "expr": "topk(10, sum(rate({namespace=~\"$namespace\"} [5m])) by (pod, container))",
                "legendFormat": "{{pod}}/{{container}}",
                "refId": "A"
              }
            ],
            "options": {
              "orientation": "horizontal",
              "displayMode": "gradient",
              "showUnfilled": true
            }
          }
        ]
      }
    }

---
# ==============================================================================
# 4. KUBERNETES TRACES DASHBOARD
# ==============================================================================
apiVersion: v1
kind: ConfigMap
metadata:
  name: grafana-dashboard-k8s-traces
  namespace: observability
data:
  k8s-traces.json: |
    {
      "title": "Kubernetes Distributed Traces",
      "uid": "k8s-traces",
      "timezone": "browser",
      "refresh": "10s",
      "time": {
        "from": "now-1h",
        "to": "now"
      },
        "templating": {
          "list": [
            {
              "name": "datasource",
              "type": "datasource",
              "query": "tempo",
              "current": {
                "text": "Tempo",
                "value": "Tempo"
              },
              "hide": 0
            },
            {
              "name": "service",
              "type": "query",
              "datasource": "$datasource",
              "query": "label_values(service.name)",
              "refresh": 2,
              "multi": false,
              "includeAll": true,
              "allValue": ".*",
              "current": {
                "text": "All",
                "value": "$__all"
              }
            },
            {
              "name": "namespace",
              "type": "query",
              "datasource": "$datasource",
              "query": "label_values(k8s.namespace.name)",
              "refresh": 2,
              "multi": false,
              "includeAll": true,
              "allValue": ".*",
              "current": {
                "text": "All",
                "value": "$__all"
              }
            }
          ]
        },
        "panels": [
          {
            "title": "Trace Search",
            "gridPos": { "h": 12, "w": 24, "x": 0, "y": 0 },
            "type": "traces",
            "datasource": "$datasource",
            "targets": [
              {
                "queryType": "search",
                "search": "service.name=~\"$service\" && k8s.namespace.name=~\"$namespace\"",
                "limit": 20,
                "refId": "A"
              }
            ]
          },
          {
            "title": "Request Rate by Service",
            "gridPos": { "h": 8, "w": 12, "x": 0, "y": 12 },
            "type": "graph",
            "datasource": "Prometheus",
            "targets": [
              {
                "expr": "sum(rate(traces_spanmetrics_calls_total{namespace=~\"$namespace\", service=~\"$service\"}[5m])) by (service, namespace)",
                "legendFormat": "{{namespace}}/{{service}}",
                "refId": "A"
              }
            ],
            "yaxes": [
              {
                "format": "reqps",
                "label": "Request/sec"
              },
              {
                "format": "short"
              }
            ]
          },
          {
            "title": "P95 Latency by Service",
            "gridPos": { "h": 8, "w": 12, "x": 12, "y": 12 },
            "type": "graph",
            "datasource": "Prometheus",
            "targets": [
              {
                "expr": "histogram_quantile(0.95, sum(rate(traces_spanmetrics_latency_bucket{namespace=~\"$namespace\", service=~\"$service\"}[5m])) by (service, namespace, le))",
                "legendFormat": "{{namespace}}/{{service}}",
                "refId": "A"
              }
            ],
            "yaxes": [
              {
                "format": "ms",
                "label": "Latency (ms)"
              },
              {
                "format": "short"
              }
            ]
          },
          {
            "title": "Error Rate by Service",
            "gridPos": { "h": 8, "w": 12, "x": 0, "y": 20 },
            "type": "graph",
            "datasource": "Prometheus",
            "targets": [
              {
                "expr": "sum(rate(traces_spanmetrics_calls_total{namespace=~\"$namespace\", service=~\"$service\", status_code=\"ERROR\"}[5m])) by (service, namespace) / sum(rate(traces_spanmetrics_calls_total{namespace=~\"$namespace\", service=~\"$service\"}[5m])) by (service, namespace) * 100",
                "legendFormat": "{{namespace}}/{{service}}",
                "refId": "A"
              }
            ],
            "yaxes": [
              {
                "format": "percent",
                "label": "Error Rate %"
              },
              {
                "format": "short"
              }
            ]
          },
          {
            "title": "Service Dependencies",
            "gridPos": { "h": 8, "w": 12, "x": 12, "y": 20 },
            "type": "nodeGraph",
            "datasource": "$datasource",
            "targets": [
              {
                "queryType": "serviceMap",
                "refId": "A"
              }
            ]
          },
          {
            "title": "Trace Duration Distribution",
            "gridPos": { "h": 8, "w": 24, "x": 0, "y": 28 },
            "type": "heatmap",
            "datasource": "Prometheus",
            "targets": [
              {
                "expr": "sum(increase(traces_spanmetrics_latency_bucket{namespace=~\"$namespace\", service=~\"$service\"}[1m])) by (le)",
                "format": "heatmap",
                "legendFormat": "{{le}}",
                "refId": "A"
              }
            ],
            "options": {
              "calculate": false,
              "cellGap": 1,
              "cellRadius": 2,
              "color": {
                "scheme": "Spectral",
                "mode": "spectrum"
              },
              "yAxis": {
                "format": "ms"
              }
            }
          }
        ]
      }
    }

---
# ==============================================================================
# 5. UPDATE GRAFANA DEPLOYMENT WITH DASHBOARD PROVISIONING
# ==============================================================================
apiVersion: apps/v1
kind: Deployment
metadata:
  name: grafana
  namespace: observability
spec:
  replicas: 1
  selector:
    matchLabels:
      app: grafana
  template:
    metadata:
      labels:
        app: grafana
    spec:
      securityContext:
        fsGroup: 472
        runAsUser: 472
      containers:
      - name: grafana
        image: grafana/grafana:latest
        ports:
        - containerPort: 3000
          name: http
        env:
        - name: GF_SECURITY_ADMIN_PASSWORD
          value: "admin"
        - name: GF_USERS_ALLOW_SIGN_UP
          value: "false"
        - name: GF_SERVER_ROOT_URL
          value: "http://localhost:3000"
        - name: GF_INSTALL_PLUGINS
          value: "grafana-clock-panel"
        volumeMounts:
        - name: grafana-datasources
          mountPath: /etc/grafana/provisioning/datasources
        - name: grafana-dashboard-provisioning
          mountPath: /etc/grafana/provisioning/dashboards
        - name: grafana-dashboards-k8s-metrics
          mountPath: /var/lib/grafana/dashboards/k8s-metrics.json
          subPath: k8s-metrics.json
        - name: grafana-dashboards-k8s-logs
          mountPath: /var/lib/grafana/dashboards/k8s-logs.json
          subPath: k8s-logs.json
        - name: grafana-dashboards-k8s-traces
          mountPath: /var/lib/grafana/dashboards/k8s-traces.json
          subPath: k8s-traces.json
        - name: grafana-storage
          mountPath: /var/lib/grafana
        resources:
          requests:
            cpu: 100m
            memory: 128Mi
          limits:
            cpu: 500m
            memory: 512Mi
        livenessProbe:
          httpGet:
            path: /api/health
            port: 3000
          initialDelaySeconds: 60
          periodSeconds: 10
        readinessProbe:
          httpGet:
            path: /api/health
            port: 3000
          initialDelaySeconds: 60
          periodSeconds: 10
      volumes:
      - name: grafana-datasources
        configMap:
          name: grafana-datasources
      - name: grafana-dashboard-provisioning
        configMap:
          name: grafana-dashboard-provisioning
      - name: grafana-dashboards-k8s-metrics
        configMap:
          name: grafana-dashboard-k8s-metrics
      - name: grafana-dashboards-k8s-logs
        configMap:
          name: grafana-dashboard-k8s-logs
      - name: grafana-dashboards-k8s-traces
        configMap:
          name: grafana-dashboard-k8s-traces
      - name: grafana-storage
        persistentVolumeClaim:
          claimName: grafana-storage

---
apiVersion: v1
kind: Service
metadata:
  name: grafana
  namespace: observability
spec:
  selector:
    app: grafana
  type: LoadBalancer
  ports:
  - name: http
    port: 3000
    targetPort: 3000

---
# ==============================================================================
# 7. OPENTELEMETRY INSTRUMENTATION
# ==============================================================================
apiVersion: opentelemetry.io/v1alpha1
kind: Instrumentation
metadata:
  name: otel-instrumentation
  namespace: observability
spec:
  exporter:
    endpoint: http://10.103.50.185:4318
  
  propagators:
    - tracecontext
    - baggage
    - b3
  
  sampler:
    type: parentbased_traceidratio
    argument: "1.0"
  
  java:
    image: ghcr.io/open-telemetry/opentelemetry-operator/autoinstrumentation-java:latest
    env:
      - name: OTEL_EXPORTER_OTLP_ENDPOINT
        value: http://10.103.50.185:4318
      - name: OTEL_EXPORTER_OTLP_PROTOCOL
        value: http/protobuf
  
  python:
    image: ghcr.io/open-telemetry/opentelemetry-operator/autoinstrumentation-python:latest
    env:
      - name: OTEL_EXPORTER_OTLP_ENDPOINT
        value: http://10.103.50.185:4318
      - name: OTEL_EXPORTER_OTLP_PROTOCOL
        value: http/protobuf
  
  nodejs:
    image: ghcr.io/open-telemetry/opentelemetry-operator/autoinstrumentation-nodejs:latest
    env:
      - name: OTEL_EXPORTER_OTLP_ENDPOINT
        value: http://10.103.50.185:4318
      - name: OTEL_EXPORTER_OTLP_PROTOCOL
        value: http/protobuf
  
  dotnet:
    image: ghcr.io/open-telemetry/opentelemetry-operator/autoinstrumentation-dotnet:latest
    env:
      - name: OTEL_EXPORTER_OTLP_ENDPOINT
        value: http://10.103.50.185:4318
      - name: OTEL_EXPORTER_OTLP_PROTOCOL
        value: http/protobuf
  
  go:
    image: ghcr.io/open-telemetry/opentelemetry-go-instrumentation/autoinstrumentation-go:latest
    env:
      - name: OTEL_EXPORTER_OTLP_ENDPOINT
        value: http://10.103.50.185:4318
      - name: OTEL_EXPORTER_OTLP_PROTOCOL
        value: http/protobuf

---
# ==============================================================================
# 8. RBAC FOR GRAFANA ALLOY
# ==============================================================================
apiVersion: v1
kind: ServiceAccount
metadata:
  name: grafana-alloy
  namespace: observability

---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  name: grafana-alloy
rules:
- apiGroups: [""]
  resources:
  - nodes
  - nodes/proxy
  - nodes/metrics
  - services
  - endpoints
  - pods
  - events
  - namespaces
  verbs: ["get", "list", "watch"]
- apiGroups: [""]
  resources:
  - pods/log
  verbs: ["get", "list", "watch"]
- apiGroups: [""]
  resources:
  - configmaps
  verbs: ["get"]
- apiGroups: ["apps"]
  resources:
  - deployments
  - daemonsets
  - replicasets
  - statefulsets
  verbs: ["get", "list", "watch"]
- nonResourceURLs: ["/metrics", "/metrics/cadvisor"]
  verbs: ["get"]

---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: grafana-alloy
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: grafana-alloy
subjects:
- kind: ServiceAccount
  name: grafana-alloy
  namespace: observability

---
# ==============================================================================
# 9. GRAFANA ALLOY - OpenTelemetry Collector (DaemonSet)
# ==============================================================================
apiVersion: v1
kind: ConfigMap
metadata:
  name: alloy-config
  namespace: observability
data:
  config.alloy: |
    logging {
      level  = "info"
      format = "logfmt"
    }
    
    // ========================================================================
    // LOGS - Collect from Kubernetes pods
    // ========================================================================
    
    discovery.kubernetes "pods" {
      role = "pod"
    }
    
    discovery.relabel "pod_logs" {
      targets = discovery.kubernetes.pods.targets
      
      rule {
        source_labels = ["__meta_kubernetes_namespace"]
        target_label  = "namespace"
      }
      
      rule {
        source_labels = ["__meta_kubernetes_pod_name"]
        target_label  = "pod"
      }
      
      rule {
        source_labels = ["__meta_kubernetes_pod_container_name"]
        target_label  = "container"
      }
      
      rule {
        source_labels = ["__meta_kubernetes_pod_label_app"]
        target_label  = "app"
      }
    }
    
    loki.source.kubernetes "pods" {
      targets    = discovery.relabel.pod_logs.output
      forward_to = [loki.write.default.receiver]
    }
    
    loki.write "default" {
      endpoint {
        url = "http://loki.observability.svc.cluster.local:3100/loki/api/v1/push"
      }
    }
    
    // ========================================================================
    // TRACES - OTLP
    // ========================================================================
    
    otelcol.receiver.otlp "default" {
      grpc {
        endpoint = "0.0.0.0:4317"
      }
      
      http {
        endpoint = "0.0.0.0:4318"
      }
      
      output {
        traces  = [otelcol.processor.batch.default.input]
        metrics = [otelcol.processor.batch.default.input]
        logs    = [otelcol.processor.batch.default.input]
      }
    }
    
    otelcol.processor.batch "default" {
      output {
        traces  = [otelcol.exporter.otlp.tempo.input]
        metrics = [otelcol.exporter.prometheus.default.input]
        logs    = [otelcol.exporter.loki.default.input]
      }
    }
    
    otelcol.exporter.otlp "tempo" {
      client {
        endpoint = "tempo.observability.svc.cluster.local:4317"
        tls {
          insecure = true
        }
      }
    }
    
    otelcol.exporter.prometheus "default" {
      forward_to = [prometheus.remote_write.default.receiver]
    }
    
    otelcol.exporter.loki "default" {
      forward_to = [loki.write.default.receiver]
    }
    
    // ========================================================================
    // METRICS
    // ========================================================================
    
    discovery.kubernetes "pods_metrics" {
      role = "pod"
    }
    
    discovery.kubernetes "nodes" {
      role = "node"
    }
    
    prometheus.scrape "pods" {
      targets    = discovery.kubernetes.pods_metrics.targets
      forward_to = [prometheus.remote_write.default.receiver]
      
      clustering {
        enabled = true
      }
    }
    
    prometheus.scrape "kubelet" {
      targets    = discovery.kubernetes.nodes.targets
      forward_to = [prometheus.remote_write.default.receiver]
      scheme     = "https"
      bearer_token_file = "/var/run/secrets/kubernetes.io/serviceaccount/token"
      
      tls_config {
        insecure_skip_verify = true
      }
    }
    
    prometheus.scrape "cadvisor" {
      targets           = discovery.kubernetes.nodes.targets
      forward_to        = [prometheus.remote_write.default.receiver]
      metrics_path      = "/metrics/cadvisor"
      scheme            = "https"
      bearer_token_file = "/var/run/secrets/kubernetes.io/serviceaccount/token"
      
      tls_config {
        insecure_skip_verify = true
      }
    }
    
    prometheus.remote_write "default" {
      endpoint {
        url = "http://prometheus.observability.svc.cluster.local:9090/api/v1/write"
      }
    }

---
apiVersion: apps/v1
kind: DaemonSet
metadata:
  name: grafana-alloy
  namespace: observability
spec:
  selector:
    matchLabels:
      app: grafana-alloy
  template:
    metadata:
      labels:
        app: grafana-alloy
    spec:
      serviceAccountName: grafana-alloy
      containers:
      - name: alloy
        image: grafana/alloy:latest
        args:
          - run
          - /etc/alloy/config.alloy
          - --storage.path=/var/lib/alloy/data
          - --server.http.listen-addr=0.0.0.0:12345
        env:
        - name: HOSTNAME
          valueFrom:
            fieldRef:
              fieldPath: spec.nodeName
        ports:
        - containerPort: 12345
          name: http
        - containerPort: 4317
          name: otlp-grpc
        - containerPort: 4318
          name: otlp-http
        volumeMounts:
        - name: config
          mountPath: /etc/alloy
          readOnly: true
        - name: data
          mountPath: /var/lib/alloy/data
        - name: varlog
          mountPath: /var/log
          readOnly: true
        - name: varlibdockercontainers
          mountPath: /var/lib/docker/containers
          readOnly: true
        - name: etcmachineid
          mountPath: /etc/machine-id
          readOnly: true
        resources:
          requests:
            cpu: 100m
            memory: 128Mi
          limits:
            cpu: 500m
            memory: 512Mi
        securityContext:
          runAsUser: 0
          privileged: true
      volumes:
      - name: config
        configMap:
          name: alloy-config
          items:
          - key: config.alloy
            path: config.alloy
      - name: data
        emptyDir: {}
      - name: varlog
        hostPath:
          path: /var/log
      - name: varlibdockercontainers
        hostPath:
          path: /var/lib/docker/containers
      - name: etcmachineid
        hostPath:
          path: /etc/machine-id
          type: FileOrCreate
      tolerations:
      - effect: NoSchedule
        operator: Exists

---
apiVersion: v1
kind: Service
metadata:
  name: grafana-alloy
  namespace: observability
spec:
  selector:
    app: grafana-alloy
  ports:
  - name: http
    port: 12345
    targetPort: 12345
  - name: otlp-grpc
    port: 4317
    targetPort: 4317
  - name: otlp-http
    port: 4318
    targetPort: 4318
  type: ClusterIP
